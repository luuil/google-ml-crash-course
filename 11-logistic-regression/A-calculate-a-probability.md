## 逻辑回归 (Logistic Regression)：计算概率

预计用时：10 分钟

许多问题需要将概率估算值作为输出。逻辑回归是一种极其高效的概率计算机制。实际上，您可以通过下两种方式之一使用返回的概率：

- “按原样”
- 转换成二元类别。

我们来了解一下如何“按原样”使用概率。假设我们创建一个逻辑回归模型来预测狗在半夜发出叫声的概率。我们将此概率称为：

```
  p(bark | night)
```

如果逻辑回归模型预测 `p(bark | night)` 的值为 0.05，那么一年内，狗的主人应该被惊醒约 18 次：

```
  startled = p(bark | night) * nights
  18 ~= 0.05 * 365
```

在很多情况下，您会将逻辑回归输出映射到二元分类问题的解决方案，该二元分类问题的目标是正确预测两个可能的标签（例如，“垃圾邮件”或“非垃圾邮件”）中的一个。之后的[单元][inner-classification]会重点介绍这一内容。

您可能想知道逻辑回归模型如何确保输出值始终落在 0 和 1 之间。巧合的是，S 型函数生成的输出值正好具有这些特性，其定义如下：

```
    y = 1 / (1 + e^−z)
```

S 型函数会产生以下曲线图：

![S function][p-sfunc-2]

**图 1：S 型函数。**

如果 z 表示使用逻辑回归训练的模型的线性层的输出，则 S 型(z) 函数会生成一个介于 0 和 1 之间的值（概率）。用数学方法表示为：

```
    y′ = 1 / (1 + e^−z)
```
 
其中：

- `y'`: 是逻辑回归模型针对特定样本的输出。
- `z` 是 `b + w1*x1 + w2*x2 + … wN*xN`
    - “w”值是该模型学习的权重和偏差。
    - “x”值是特定样本的特征值。

请注意，`z` 也称为对数几率，因为 S 型函数的反函数表明，z 可定义为标签“1”（例如“狗叫”）的概率除以标签“0”（例如“狗不叫”）的概率得出的值的对数：

```
    z = log( y/(1−y) )
```

以下是具有机器学习标签的 S 型函数：

![S function][p-sfunc-3]

**图 2：逻辑回归输出。**


### 推导计算

假设我们的逻辑回归模型具有学习了下列偏差和权重的三个特征：

```
    b = 1
    w1 = 2
    w2 = -1
    w3 = 5
```

进一步假设给定样本具有以下特征值：

```
    x1 = 0
    x2 = 10
    x3 = 2
```

因此，对数几率：

```
    b+w1x1+w2x2+w3x3
```

将是：

```
    (1) + (2)(0) + (-1)(10) + (5)(2) = 1
```
因此，此特定样本的逻辑回归预测值将是 0.731：

```
    y′ = 1 / (1 + e^−1) = 0.731
```

![S function][p-sfunc-4]

[p-sfunc-2]: ../image/11-A-sfunction-2.png
[p-sfunc-3]: ../image/11-A-sfunction-3.png
[p-sfunc-4]: ../image/11-A-sfunction-4.png
[inner-classification]: ../12-classification/README.MD