## 逻辑回归 (Logistic Regression)

逻辑回归会生成一个介于 0 到 1 之间（不包括 0 和 1）的概率值，而不是确切地预测结果是 0 还是 1。以用于检测垃圾邮件的逻辑回归模型为例。如果此模型推断某一特定电子邮件的值为 0.932，则意味着该电子邮件是垃圾邮件的概率为 93.2%。更准确地说，这意味着在无限训练样本的极限情况下，模型预测其值为 0.932 的这组样本实际上有 93.2% 是垃圾邮件，其余的 6.8% 不是垃圾邮件。

预计用时：4 分钟

### 学习目标

- 了解逻辑回归。
- 了解逻辑回归的损失和正则化函数。

### 对抛硬币的结果进行预测？

- 想象一下预测弯曲的硬币正面朝上的概率这一问题
- 您可能会用到弯曲角度、硬币质量等特征。
- 您可以使用的最简单的模型是哪个模型？
- 什么地方可能会出错？

### 逻辑回归

- 许多问题需要将概率估算值作为输出
- 输入逻辑回归
- 很方便，因为概率估算值已经过校准
    - 例如，p（待出售房屋）* 价格 = 预期结果
- 此外，它在我们需要二元分类时非常有用
    - 垃圾邮件或非垃圾邮件？→ p（垃圾邮件）

### 逻辑回归 - 预测

```
y′= 1 / { 1 + e^−(wTx+b) }
``` 

Where: 

- `x`: 提供熟悉的线性模型
- `1+e−(...)`: 应用 S 型函数

![S function][p-sfunc-1]

### 对数损失函数的定义

![loss function][p-lossfunc-1]

### 逻辑回归和正则化

- 正则化对于逻辑回归而言至关重要。
    - 记住渐近线
    - 它会不断尝试促使损失在高维度空间内达到 0
- 以下两个策略尤其有用：
    - L2 正则化（也称为 L2 权重衰减）- 用于降低超大权重。
    - 早停法 - 用于限制训练步数或学习速率。

### 线性逻辑回归

- 线性逻辑回归极其高效。
    - 超快的训练速度和较短的预测时间。
    - 短模型/宽度模型占用大量 RAM。


[p-sfunc-1]: ../image/11-A-sfunction-1.png
[p-lossfunc-1]: ../image/11-A-loss-function-1.png