## 简化正则化 (Regularization for Simplicity)

正则化指的是降低模型的复杂度以减少过拟合。

预计用时：5 分钟

### 学习目标

- 了解复杂度与泛化之间的权衡。
- 使用 L2 正则化进行实验。

### 泛化曲线

![regular][p-regular-1]

训练集的损失函数逐渐下降。相比之下，验证集的损失函数先下降，然后开始上升。

这其实就是对训练数据**过拟合**了.

> 解决过拟合问题的一种策略是早停法, 也就是在训练数据的效果实际收敛前停止训练.
> 但在实际中操作困难.

### 降低模型的复杂度

- 我们希望尽可能降低模型的复杂度。
- 我们可以将这种想法纳入训练时所进行的优化中。
- 经验风险最小化：
    - 旨在减少训练误差
    ```
    minimize: Loss(Data|Model)
    ```
- 结构风险最小化：
    - 旨在减少训练误差, 同时平衡复杂度
    ```
    minimize: Loss(Data|Model)+complexity(Model)
    ```

### 正则化

如何定义复杂度（模型）？

- 首选较小的权重
- 可以通过 L2 正则化（也称为岭正则化）对这种想法进行编码
    - 复杂度（模型）= 权重的平方和
    - 除去非常大的权重
    - 对于线性模型：首选比较平缓的斜率
    - 贝叶斯先验概率：
        - 权重应该以 0 为中心
        - 权重应该呈正态分布

### L2 正则化的损失函数

```
    L(w,D) + λ*||w||^2_2
```

Where:

- 第一项: 损失项, 取决于训练数据
    - `L`: 旨在减少训练误差
- 第二项: 正则化项, 与数据无关, 只为衡量模型复杂度
    - `λ`: 控制上述两项的平衡
    - `w`: 平衡复杂度
    - `^2_2`: 权重标准化的L2平方

### 更多

- [L2 regularization](A-l2-regularization.md)
- [Lambda](B-lambda.md)

[p-regular-1]: ../image/10-A-regular-1.png